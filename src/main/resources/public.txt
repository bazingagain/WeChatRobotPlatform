请按照格式：  关键词--回复内容(一行)    来编写~
公共关键词--公共关键词回复
<list>问题分类--1.课程信息问题列表、2.认识数据问题列表、3.作业1问题列表、4.聚类知识点问题列表
<list>课程信息问题列表--5.上课时间及地点、6.教师信息、7.朱老师联系方式、8.助教信息、9.课程主要内容、10.课程如何打分、11.考勤如何算分、12.上课没法开是否要请假、13.模式识别第一次作业提交截止时间、14.作业系统出错了怎么办
上课时间及地点--周五3-4节4-504 或 周五6-7节4-404 （1-18周）
教师信息--朱卫平副教授，楚天学子，珞珈青年学者。博士毕业于香港理工大学；曾经工作于东方海外上海研发中心，香港大学电子商业技术研究所，法国IRISA研究所, 香港理工大学 研究方向包括有：RFID与传感器技术, 分布式计算，云计算，大数据获取与分析。
朱老师联系方式--办公室: 英语教学中心（ A3-4机房旁边）大数据与云计算实验室 Email: wpzhu@whu.edu.cn QQ: 46152597 TEL: 17092616976 主页：http://www.bdcclab.com/wpzhu.htm
助教信息--上午助教以及QQ：李铭哲540886656，邓娜997813969, 余迎港944585862；下午助教以及QQ：傅永健1524630725，李耀东2507032911，秦江波1105351275
课程主要内容--模式识别概论，统计模式识别，模糊模式识别法，神经网络模式识别法
课程如何打分--课后作业2次，每次15分，考勤20分，期末考试50分（开卷）
考勤如何算分--到课80%以上算全勤，给满分，少于此按比例扣分
上课没法开是否要请假--到课80%以上算全勤，有一定弹性，在此范围内缺勤无需请假
模式识别第一次作业提交截止时间--2017年11月10日（周五）
作业系统出错了怎么办--作业系统任何问题请联系 杨耀航 QQ:1562360593

<list>认识数据问题列表--15.什么是数据集和数据对象、16.什么是数据的属性、17.数据的属性有哪些类型、18.什么是标称属性、19.什么是二元属性、20.什么是对称二元属性、21.什么是非对称二元属性、22.非对称二元属性中怎么区分那个重要不重要、23.为什么要区分二元属性的对称和非对称、24.什么是序数属性、25.什么是数值属性、26.什么是区间标度属性、27.什么是比率标度属性、28.什么是离散属性、29.衡量中心性的测量有哪些、30.什么是截尾均值、31.什么是中位数、32.如果数据是偶数，中位数怎么算、33.何时使用中位数作为中心性测量、34.什么是众数峰值、35.什么是中列数、36.什么是正偏斜、37.什么是负偏斜、38.什么是偏斜、39.什么是极差、40.什么是分位数、41.什么是四分位数极差、42.什么是IQR、43.什么是五数概括、44.五数概括中如何去除离群点、45.五数概括中离群点要画出来么、46.五数概括中最小值和最大值为什么有时不是最大或最小的值、47.何时考虑标准差才是有意义的、48.什么是分位数图、49.分位数-分位数图有什么用、50.什么是相异性矩阵、51.数据可视化有哪些方法、52.标称属性的相异性度量、53.不对称二元属性的相异性度量有什么特别之处、54.数值属性的相异性如何度量、55.什么是上确界距离、56.上确界距离如何计算、57.序数属性的相异性如何计算、58.混合类型属性的相异性如何计算
什么是数据集和数据对象--数据集是由数据对象构成的，一个数据对象表示一个实体，用属性来描述。
什么是数据的属性--属性表示数据对象的一个特征。
数据的属性有哪些类型--属性的类型是有属性可取的值决定的，有标称的、二元的、序数的或者数值的各种类型。
什么是标称属性--标称属性(nomimal attribute)是事物的标号或者名称。值没有序的关系。每一个值表示类别、编码或者状态。
什么是二元属性--二元属性是一种标称属性，只有两个类别或状态：0和1。
什么是对称二元属性--如果二进制属性的两个状态是同等有价值的具有相同的权重，则为对称的
什么是非对称二元属性--如果两个状态不是同等重要的，则为非对称的。比如HIV检查的结果呈阴性和阳性。
非对称二元属性中怎么区分那个重要不重要--出现较少的属性更重要
为什么要区分二元属性的对称和非对称--非对称二元属性中占不重要地位的属性需要在计算中进行特别处理以突出占重要地位的属性的影响
什么是序数属性--序数属性具有次序或者级别的值。但是相邻值之间的差是未知的。
什么是数值属性--数值型属性是定量的，是可测量的数值。
什么是区间标度属性--区间标度属性使用同等大小的单元来衡量。除了能对属性值排序，还可以比较和衡量不同值的差值大小，但是不能计算两个属性的比率。
什么是比率标度属性--比率标度属性是有固定的0值的数值属性。可以以比率来衡量两个值，也可以计算值的差值
什么是离散属性--离散属性是有限的或者可数的值的集合
衡量中心性的测量有哪些--均值、中值、众数和中列数。
什么是截尾均值--为了处理由少数极端值带来的效果，可以使用削减均值，即去掉极端大和极端小的值之后的平均值。比如，把薪水排序，然后去掉2%的最大值和最小值。
什么是中位数--中位数是一系列排序好的数据的中点的值。该值把数据集分成2个部分，一半值大的，一半值小的
如果数据是偶数，中位数怎么算--中值可以是中点的2个值中的任意值，或者是取两个中点数的均值（如果可以取均值）。
何时使用中位数作为中心性测量--对于偏斜（不对称）的数据，使用中位数（中值）(median)是更好的中心性测量。
什么是众数峰值--有可能好几个不同的值都出现大量的频率，导致众数不止一个。众数有1个、2个、3个的分别称为unimodal（单峰值）, bimodal（二峰值）, trimodal（三峰值）
什么是中列数--中列数(midrange)是数据集中最大值和最小值的平均值。可以用来评估数值型数据的中心性趋势。
什么是正偏斜--如果众数的值小于中值，称为正偏斜；
什么是负偏斜--如果众数的值大于中值，称为负偏斜
什么是偏斜--如果众数的值小于中值，称为正偏斜；如果众数的值大于中值，称为负偏斜
什么是极差--令x1, x2, … xN是某个数值属性X的一系列观察，数据集的极差表示的是最大值和最小值的差。
什么是分位数--分位数是数据分布上有一定间隔的数据点，将数据分成基本相等大小的连续数据集。如，2分位点把数据划分为高低两半。即中位数。
什么是四分位数极差--四分位数中Q1和Q3的距离，简单反应了数据中心的一半数据的范围。这个距离被称为四分位数极差（IQR）
什么是IQR--四分位数中Q1和Q3的距离，简单反应了数据中心的一半数据的范围。这个距离被称为四分位数极差（IQR）
什么是五数概括--五数概括（Five-number summary）由中值，Q1， Q3，最小值和最大值组成，按次序表示为：Minimum, Q1, Median, Q3, Maximum。
五数概括中如何去除离群点--第一分位数之下或第三分位数之上1.5*IQR的值
五数概括中离群点要画出来么--也要画出来
五数概括中最小值和最大值为什么有时不是最大或最小的值--五数概括中最小值和最大值是去除了离群点后计算的
标准差的大小代表着什么--方差和标准差是测量数据分散度的。比较低的标准差表示数据观察倾向于靠近均值。高标准差表示数据值分布在一个比较大的范围区间。
何时考虑标准差才是有意义的--标准差测量的是数据偏离均值的发散程度，因此只有在均值接近数据中心的时候才考虑。
什么是分位数图--分位数图显示了给定属性的所有数据和分位数信息。每个观测值xi与一个百分数fi配对，指出大约fi ×100%的数据小于xi
分位数-分位数图有什么用--可以比较两个对象分位数的区别
什么是相异性矩阵--相异性矩阵，存放n个对象两两之间的邻近度，d(i,j) 越趋近于0，对象越相同
数据可视化有哪些方法--分位数图，直方图，散点图，热度图，还有基于图符的可视化技术等。
标称属性的相异性度量--两个对象i和j之间的相异性可以根据不匹配率来计算， 定义为不匹配的属性数目除以属性总数。两个对象相应的属性如果值相同称为匹配，否则为不匹配
不对称二元属性的相异性度量有什么特别之处--不匹配率计算时分母中将去除负匹配的数目 （也就是两个都取0值得情况）
数值属性的相异性如何度量--数值属性相异性的距离度量包括欧几里得距离、曼哈顿距离和闵可夫斯基距离等
什么是上确界距离--上确界距离（又称Lmax, L∞ 范数,切比雪夫距离）是h->∞时的闵可夫斯基距离
上确界距离如何计算--实际是取得差距最多的那个属性对应的差距
序数属性的相异性如何计算--将每个值用它的排位进行替换，同时进行标准化处理，处理方式是排位减去1再除以属性取值总个数减去1. 在此之后转化为数值型属性差异性计算处理
混合类型属性的相异性如何计算--不同的属性差异性需要标准化到共同的区间[0.0,1.0]上，然后混合在一起。具体计算请参见PPT


<list>作业1问题列表--59.作业中混合型数据要怎么输入呢、60.问一下那个差异性矩阵计算，输入是什么啊、61.关于二元属性的度量，是用户通过自己输入来规定了1和0，然后程序自动把对应的数据转换为0和1，比较计算得出q r s t的值，这样对吧？ （比如有值 P， Y ，N，然后设置P和Y为1，N为0）、62.关于非对称二元属性，在混合类型属性的相异性矩阵计算中，是对所有的非对称二元属性计算出一个相异性矩阵，还是对每一列的非对称二元属性分别写出0-1相异性矩阵呢?、63.请问混合型数据差异性矩阵计算中二元属性的相异性计算可以和标称属性归为一类吗、64.计算混合属性的差异性矩阵时是不是还得标明每个属性各属于什么类型、65.输入标称属性的时候要直接给属性赋值吗，还是需要解析、66.isodata 第十三步 合并 是怎么个意思，是一直合并一直达到允许合并的最大对数（那一个聚类中心 到另外两个聚类中心的距离都小于 两聚类中心的最短距离怎么办）；还是怎么样、67.分别计算每个聚类中心之间的距离，假设聚类中心1 和2合并了， 1和3也符合合并要求 ，怎么处理
作业中混合型数据要怎么输入呢--可以自己自由设计，读取文件，命令行输入，数据库等各种方法都可以
问一下那个差异性矩阵计算，输入是什么啊--可以自己自由设计，读取文件，命令行输入，数据库等各种方法都可以
关于二元属性的度量，是用户通过自己输入来规定了1和0，然后程序自动把对应的数据转换为0和1，比较计算得出q r s t的值，这样对吧？ （比如有值 P， Y ，N，然后设置P和Y为1，N为0）--对
关于非对称二元属性，在混合类型属性的相异性矩阵计算中，是对所有的非对称二元属性计算出一个相异性矩阵，还是对每一列的非对称二元属性分别写出0-1相异性矩阵呢?--计算出总体的一个矩阵
请问混合型数据差异性矩阵计算中二元属性的相异性计算可以和标称属性归为一类吗--可以，但要注意非对称二元属性的特殊处理
计算混合属性的差异性矩阵时是不是还得标明每个属性各属于什么类型--可以自由设计，如自己识别（更智能），也可以标注（需要人工参与）
输入标称属性的时候要直接给属性赋值吗，还是需要解析--空
isodata 第十三步 合并 是怎么个意思，是一直合并一直达到允许合并的最大对数（那一个聚类中心 到另外两个聚类中心的距离都小于 两聚类中心的最短距离怎么办）；还是怎么样 --如果类1合并了，1就不存在了，也就无法和别的类合并了。在一次迭代中，某一类最多只能合并一次
分别计算每个聚类中心之间的距离，假设聚类中心1 和2合并了， 1和3也符合合并要求 ，怎么处理--如果1合并了，1就不存在了，也就无法和别的类合并了。在一次迭代中，某一类最多只能合并一次
<list>聚类知识点问题列表--68.什么是聚类、69.为什么说聚类是一种无监督学习、70.聚类是否一定不使用样本的分类标签、71.对聚类的典型要求有哪些、72.聚类的目标是什么、73.聚类的性能标准是什么、74.相似性如何理解、75.样本间距离如何确定、76.欧氏距离是什么、77.闵可夫斯基距离是什么、78.闵可夫斯基距离与欧氏距离关系、79.闵可夫斯基距离与曼哈顿距离关系、80.什么是街坊距离、81.什么是曼哈顿距离、82.马氏距离是什么、83.汉明距离是什么、84.角度相似性函数是什么、85.Tanimoto测度是什么、86.如何确定离散属性的距离、87.为什么要做预处理、88.聚类准则是什么、89.聚类准则有哪两种、90.课堂上用的聚类准则函数时哪个、91.最小类内误差平方和函数的适用范围如何、92.基于距离阈值的近邻聚类法是什么、93.基于距离阈值的近邻聚类法中的阈值和起始点如何选择、94.最大最小距离算法是什么、95.最大最小距离算法中的阈值如何设置、96.层次聚类法是什么、97.层次聚类法中两个类之间的距离如何计算、98.类间距离有哪些表示方式、99.类间距离计算中最短距离的适用范围、100.类间距离计算中最长距离的适用范围、101.层次聚类法的结束条件有哪些、102.K-均值算法是什么、103.K-中心点算法是什么、104.为什么要设计K-中心点算法、105.K-中心点算法与K-均值算法的区别有哪些、106.为什么需要动态聚类算法、107.K-均值算法计算过程中聚类个数和聚类中心是否发生变化、108.K-中心点算法计算过程中聚类个数和聚类中心是否发生变化、109.K-均值聚类算法优缺点有哪些、110.Iso-data算法是什么、111.Iso-data有哪些预设参数、112.Iso-data第七步如何判断合并还是分裂、113.聚类性能衡量的标准有哪些、114.降维的指导思想是什么、115.什么是中心化、116.Iso-data算法与k-mean算法的不同
什么是聚类--聚类（cluster analysis）是无监督学习中的一种任务。聚类试图依靠数据的内在性质与联系，将样本集划分为子集。每个子集是一个簇（cluster），使得簇中的对象彼此相似，但与其他簇中的对象很不相似。
为什么说聚类是一种无监督学习--聚类是一种无监督的学习，是说该方法事先不知道样本的类别标签，通过对相关属性的分析，将具有类似属性的样本聚成一类。
聚类是否一定不使用样本的分类标签--并不一定。聚类在训练时也可能使用物品的类别标签，但是类别标签仅仅起到辅助作用，并不直接决定聚类结果。例如，Learning Vector Quantization方法在训练时会将物品的类别作为聚类结果的参考，对当前训练出的学习器参数进行调整。
对聚类的典型要求有哪些--要求有很多，包括处理不同属性类型的能力，聚类高维数据的能力，处理基于约束的聚类能力，处理复杂的簇，具有可伸缩性，发现任意形状的簇，对于确定输入参数的领域知识的要求，处理噪声数据的能力，增量聚类和对输入次序不敏感，可解释性和可用性等等。
聚类的目标是什么--聚类的目标或是性能标准难以一概而论。相对而言大多数聚类任务的目标还是要找到类内相似度高而类间相似度低的划分方式。基于此我们可以设计各种指标来衡量。此外，还可以与预想中的分类结果比较，也就是以某个算法作为分类的依据和标准，将新的算法与其结果进行比较。
聚类的性能标准是什么--聚类的目标或是性能标准难以一概而论。相对而言大多数聚类任务的目标还是要找到类内相似度高而类间相似度低的划分方式。基于此我们可以设计各种指标来衡量。此外，还可以与预想中的分类结果比较，也就是以某个算法作为分类的依据和标准，将新的算法与其结果进行比较。
相似性如何理解--假设每个样本有n个特征值，它们组成的n维向量称为该样本的特征向量。它相当于特征空间中的一个点。以特征空间中，点间的距离函数作为模式相似性的测量，以“距离”作为模式分类的依据，距离越小，越“相似”。
样本间距离如何确定--距离通常是样本各项属性的一个函数。通常这个函数要满足非负性、同一性（仅与自己的距离为0），对称性以及三角不等式。不过，实际上在聚类任务中的距离不需要严格满足上述条件，尤其是三角不等式。例如，人类与狼类在聚类任务中的距离可能远远大于人类与狼人、狼人与狼类的距离之和（但这不代表三角不等式不重要。如果完全不考虑三角不等式来确定距离，那么就会产生相似的样本之间的距离反而比不相似的样本大的情况）。
欧氏距离是什么--两个向量的欧氏距离定义为对应分量差值的平方和再开方<file><path>欧氏距离.jpg</file>
闵可夫斯基距离是什么--两个向量的闵可夫斯基距离定义为对应分量差值的m次方和再开m次方<file><path>闵可夫斯基距离.jpg</file>
闵可夫斯基距离与欧氏距离关系--闵可夫斯基距离m=2时就是欧氏距离
闵可夫斯基距离与曼哈顿距离关系--闵可夫斯基距离m=1时就是曼哈顿距离距离
什么是街坊距离--街坊距离就是曼哈顿距离
什么是曼哈顿距离--两个向量的曼哈顿距离定义为对应分量差值的绝对值求和
马氏距离是什么--两个向量的马氏距离平方定义为(“模式向量与均值向量之差”转置)乘以(协方差矩阵)再乘以(“模式向量与均值向量之差”)<file><path>马氏距离.jpg</file>
汉明距离是什么--两个向量的汉明距离定义为“属性总数”减去“两个向量各自分量乘积和”再除以2<file><path>汉明距离.jpg</file>
角度相似性函数是什么--两个向量的角度相似性函数实际计算的是这两个向量之间夹角的余弦。亲，请复习线性代数看看怎么求<file><path>角度相似性函数.jpg</file>
Tanimoto测度是什么--向量A和B的Tanimoto测度定义为A和B中共有的特征数目除以A和B所拥有的特征数目之和（共同的特征不重复计算）<file><path>Tanimoto测度.jpg</file>
如何确定离散属性的距离--对于一些没有顺序关系的离散属性而言，距离往往难以计算（例如，计算“圆柱体，铁制品，中空”和“长方体，木制品，实心”的距离）。这时可以将一个属性拆解成一个向量，例如，假设第一个属性有“圆柱体”，“长方体”，“圆锥体”三个可选的值，则可以将其拆解成一个包含三个0/1分量的向量。则如上两个例子的取值就分别是[1,0,0]和[0,1,0]。
为什么要做预处理--预处理是为了去除数据本身某些不好的特点。比如，有的数据集中某一个属性的单位比其他属性“小”很多，导致在数值上这个属性比其他属性要大许多，因此在运行算法的时候，这一维对结果的影响就占据了主导地位。而这并不一定是我们想要的结果，因此我们要统一数据的量纲（比如，做标准化）。此外，一些算法对数据的性质有一定的要求（如符合标准正态分布等），这也需要预处理来完成。
聚类准则是什么--根据相似性测度确定的，衡量模式之间是否相似的标准。即把不同模式聚为一类还是归为不同类的准则。
聚类准则有哪两种--1.  阈值准则：根据规定的距离阈值进行分类的准则。2.  函数准则：利用聚类准则函数进行分类的准则。
课堂上用的聚类准则函数时哪个--是最小类内误差平方和函数。其原理是对每个样本点，计算它到其所属类中心的距离平方，然后对所有的样本求和。聚类的目的是使得这个值最小。
最小类内误差平方和函数的适用范围如何--适用于各类样本密集且数目相差不多，而不同类间的样本又明显分开的情况。
基于距离阈值的近邻聚类法是什么--该方法步骤为：1）任取一个样本作为第一个聚类中心 2）计算新样本到已有聚类中心的距离，若存在与其距离小于阈值T的聚类中心，则将其归于那一类；否则令其成为新的聚类中心 3）以此类推直到所有样本都被分类
基于距离阈值的近邻聚类法中的阈值和起始点如何选择--用先验知识指导阈值和起始点的选择，可获得合理的聚类结果。否则只能选择不同的初值重复试探，并对聚类结果进行验算，根据一定的评价标准，得出合理的聚类结果。
最大最小距离算法是什么--该方法步骤为：1）任取一样本作为第一个聚类中心 2）选择与第一个聚类最远的点作为第二个聚类中心 3）逐个计算各模式样本与已确定的所有聚类中心之间的距离，并选出其中的最小距离， 4）在所有最小距离中选出最大距离，如该最大值达到一定阈值（可以定义为一个常数T,也可以定义为第一个聚类中心和第二聚类中心距离的一定比例），则相应的样本点取为新的聚类中心 5）重复步骤3和4，直到没有新的聚类中心出现为止 6）将剩余样本分到最近的聚类中心代表的类中
最大最小距离算法中的阈值如何设置--可以定义为一个常数T,也可以定义为第一个聚类中心和第二聚类中心距离的一定比例
层次聚类法是什么--1）所有样本自成一类，计算各类距离 2）将距离最小的两个类合成一类，重新计算各类距离 3）如果各类距离都大于阈值T，则停止；或不设置阈值T，直到只剩一个类才停止，返回分级树
层次聚类法中两个类之间的距离如何计算--假设类A与类B，类A与类C的距离之前已经算出，当B和C合并成一个类（假设记住类BC）时A与BC的距离可以由类A与类B的距离和类A与类C的距离计算得出，无需根据定义重新计算（重新计算也是对的，只是效率太低）
类间距离有哪些表示方式--可以用类间最长/短距离，中间距离，重心距离，类平均距离等方法。
类间距离计算中最短距离的适用范围--这是衡量类间距离最好情况，如计算类之间取得联络的通讯延迟
类间距离计算中最长距离的适用范围--这是衡量类间距离最坏情况，如要把一类中的所有数据传递给另一类时类之间的通讯延迟
层次聚类法的结束条件有哪些--基于阈值的结束或者形成完整的聚类层次树
K-均值算法是什么--该方法步骤为：1）任取k个样本作为聚类中心 2）按照最小距离原则将剩余样本分配给这些聚类中心 3）计算聚类中心为各个类的重心 4）重复2~3，直到分类情况不发生改变
K-中心点算法是什么--该方法步骤为：1) 首先随机选取一组聚类样本作为中心点集 2) 每个中心点对应一个簇 3) 计算各样本点到各个中心点的距离（如欧几里德距离），将样本点放入距离中心点最短的那个簇中	4) 计算各簇中，距簇内各样本点距离的绝度误差最小的点，作为新的中心点 5) 如果新的中心点集与原中心点集相同，算法终止；如果新的中心点集与原中心点集不完全相同，返回b)
为什么要设计K-中心点算法--K均值算法对于离群点是敏感的，因为一个有很大极端值的对象可能显著地扭曲数据的分布。平方差的使用更是严重恶化了这一影响。我们可以在每个簇中选出一个实际的对象来代表该簇。而不是利用均值
K-中心点算法与K-均值算法的区别有哪些--1.K-中心点算法的类中心只能是实际存在的点，而K-均值算法的类中心可以是虚拟的点 2.K-中心点算法在确定类中心点的时候需要检查其他点变成中心点对准则函数的影响。而K-均值算法的类中心点计算时无需准则函数
为什么需要动态聚类算法--因为动态聚类算法不需要对数据集的分布性质有很多了解。往往在定义了距离以及评判标准（欲优化的函数）之后，只需要按照算法步骤进行迭代以求取函数的最大值就可以获得较好的结果。
K-均值算法计算过程中聚类个数和聚类中心是否发生变化--聚类中心会动态变化，聚类个数不发生变化
K-中心点算法计算过程中聚类个数和聚类中心是否发生变化--聚类中心会动态变化，聚类个数不发生变化
K-均值聚类算法优缺点有哪些--优点包括 1）思想简单易行； 2）时间复杂度接近线性； 3）对大数据集，是可伸缩和有效的；缺点包括1）要求用户事先给出要生成的簇数k，不适合的k 值可能返回较差的结果；2）不适合发现非凸形状的簇，或者大小差别很大的簇； 3）对噪声和离群点敏感
Iso-data算法是什么--太复杂了，请参照PPT或者书籍P65<file><path>Iso-data算法.jpg</file>
Iso-data有哪些预设参数--<file><path>Iso-data预设参数.jpg</file>
Iso-data第七步如何判断合并还是分裂--1.偶数此合并，奇数次分裂 2.如何类数目超过或低于一定阈值，进行相关合并和分裂 3.如何迭代次数达到最大，最后进行一次合并
聚类性能衡量的标准有哪些--总体上来看，聚类算法的性能标标准可分为两大类，分别是内部标准和外部标准。内部标准主要依靠分类出的各类别的类间距离和类内散度来确定，常用的评判标准有DB指数（Davies-Bouldin index）和Dunn指数（Dunn index）。外部标准则是与一个已经存在了的参考模型的分类结果作比较，常用的标准有Jaccard系数，FM指数和Rand指数。
降维的指导思想是什么--在聚类分析时，有时候需要对数据进行降维，从而获得更为有代表性的数据，或者用来提高运算的效率。为了不影响聚类分析，降维只需要满足降维前后两两样本的距离不变（或者，满足距离的先后序关系）即可。
什么是中心化--中心化就是让所有的数据减去数据的平均值，以达到零均值的效果。某些时候，这个操作是必要的，因为某些算法可能对数据的性质有要求。
Iso-data算法与k-mean算法的不同--ISODATA算法可以看做是K-Means的一种改进，他们之间主要有两点不同：1）ISODATA算法不是每调整一个样本的类别就更新一次各类的均值，而是在把全部样本调整完后才更新计算各类的均值，相比于K-Means的逐个样本修正，这种均值的更新方法叫做成批样本修正，可以提高计算效率；2）ISODATA算法在聚类过程中引入了对类别的评判准则，可以根据这些准则自动的将某些类别合并或分裂，从而得到更合理的聚类结果，也在一定程度上打破了事先给定类别数目的限制。